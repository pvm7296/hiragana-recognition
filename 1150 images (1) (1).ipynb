{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1cb4a92",
   "metadata": {},
   "source": [
    "# Hiragana character recognition model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc54f247",
   "metadata": {},
   "source": [
    "In this model, a small image dataset of 1150 images (25 each for 46 characters) is used. As the dataset is too small to train a model efficiently, ImageDataGenerator is used on the dataset to generate more data on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad9b26f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 920 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set up data generators for training and validation data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:/Users/pridh/OneDrive/Desktop/AoML/Hiragana_images',\n",
    "    target_size=(64, 64),  # Input size for the CNN model\n",
    "    batch_size=8,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2e0835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of class indices to class names:\n",
      "0: あ\n",
      "1: い\n",
      "2: う\n",
      "3: え\n",
      "4: お\n",
      "5: か\n",
      "6: き\n",
      "7: く\n",
      "8: け\n",
      "9: こ\n",
      "10: さ\n",
      "11: し\n",
      "12: す\n",
      "13: せ\n",
      "14: そ\n",
      "15: た\n",
      "16: ち\n",
      "17: つ\n",
      "18: て\n",
      "19: と\n",
      "20: な\n",
      "21: に\n",
      "22: ぬ\n",
      "23: ね\n",
      "24: の\n",
      "25: は\n",
      "26: ひ\n",
      "27: ふ\n",
      "28: へ\n",
      "29: ほ\n",
      "30: ま\n",
      "31: み\n",
      "32: む\n",
      "33: め\n",
      "34: も\n",
      "35: や\n",
      "36: ゆ\n",
      "37: よ\n",
      "38: ら\n",
      "39: り\n",
      "40: る\n",
      "41: れ\n",
      "42: ろ\n",
      "43: わ\n",
      "44: を\n",
      "45: ん\n"
     ]
    }
   ],
   "source": [
    "# Get the mapping of class indices to class names\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_indices = train_generator.class_indices\n",
    "\n",
    "# Print the mapping of class indices to class names\n",
    "print('Mapping of class indices to class names:')\n",
    "for idx, name in enumerate(class_names):\n",
    "    print(f'{idx}: {name}')\n",
    "\n",
    "# Save the mapping of class indices to class names to a file\n",
    "with open('class_mapping.txt', 'w', encoding='utf-8') as f:\n",
    "    for idx, name in enumerate(class_names):\n",
    "        f.write(f'{idx}: {name}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae15b792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 230 images belonging to 46 classes.\n",
      "Epoch 1/20\n",
      "115/115 [==============================] - 12s 91ms/step - loss: 3.8281 - accuracy: 0.0272 - val_loss: 3.7444 - val_accuracy: 0.0870\n",
      "Epoch 2/20\n",
      "115/115 [==============================] - 3s 25ms/step - loss: 3.1563 - accuracy: 0.1902 - val_loss: 1.7471 - val_accuracy: 0.4696\n",
      "Epoch 3/20\n",
      "115/115 [==============================] - 3s 26ms/step - loss: 1.7326 - accuracy: 0.4978 - val_loss: 0.9200 - val_accuracy: 0.7174\n",
      "Epoch 4/20\n",
      "115/115 [==============================] - 3s 26ms/step - loss: 1.0133 - accuracy: 0.7120 - val_loss: 0.7540 - val_accuracy: 0.7957\n",
      "Epoch 5/20\n",
      "115/115 [==============================] - 3s 26ms/step - loss: 0.6735 - accuracy: 0.8000 - val_loss: 0.6581 - val_accuracy: 0.8304\n",
      "Epoch 6/20\n",
      "115/115 [==============================] - 3s 26ms/step - loss: 0.4749 - accuracy: 0.8522 - val_loss: 0.5333 - val_accuracy: 0.8478\n",
      "Epoch 7/20\n",
      "115/115 [==============================] - 3s 26ms/step - loss: 0.2852 - accuracy: 0.9185 - val_loss: 0.4274 - val_accuracy: 0.8826\n",
      "Epoch 8/20\n",
      "115/115 [==============================] - 3s 25ms/step - loss: 0.2347 - accuracy: 0.9326 - val_loss: 0.4309 - val_accuracy: 0.8870\n",
      "Epoch 9/20\n",
      "115/115 [==============================] - 3s 24ms/step - loss: 0.1145 - accuracy: 0.9685 - val_loss: 0.5042 - val_accuracy: 0.8609\n",
      "Epoch 10/20\n",
      "115/115 [==============================] - 3s 26ms/step - loss: 0.1906 - accuracy: 0.9500 - val_loss: 0.4441 - val_accuracy: 0.8957\n",
      "Epoch 11/20\n",
      "115/115 [==============================] - 3s 26ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.4224 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "115/115 [==============================] - 3s 25ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 0.4475 - val_accuracy: 0.8826\n",
      "Epoch 13/20\n",
      "115/115 [==============================] - 3s 25ms/step - loss: 0.0472 - accuracy: 0.9902 - val_loss: 0.3443 - val_accuracy: 0.9217\n",
      "Epoch 14/20\n",
      "115/115 [==============================] - 3s 24ms/step - loss: 0.0467 - accuracy: 0.9870 - val_loss: 0.4255 - val_accuracy: 0.9130\n",
      "Epoch 15/20\n",
      "115/115 [==============================] - 3s 24ms/step - loss: 0.1182 - accuracy: 0.9674 - val_loss: 0.5497 - val_accuracy: 0.8826\n",
      "Epoch 16/20\n",
      "115/115 [==============================] - 3s 27ms/step - loss: 0.0769 - accuracy: 0.9826 - val_loss: 0.5888 - val_accuracy: 0.8739\n",
      "Epoch 17/20\n",
      "115/115 [==============================] - 3s 26ms/step - loss: 0.1225 - accuracy: 0.9630 - val_loss: 0.4616 - val_accuracy: 0.8826\n",
      "Epoch 18/20\n",
      "115/115 [==============================] - 3s 26ms/step - loss: 0.1427 - accuracy: 0.9554 - val_loss: 0.5413 - val_accuracy: 0.8522\n",
      "Epoch 19/20\n",
      "115/115 [==============================] - 3s 23ms/step - loss: 0.0413 - accuracy: 0.9870 - val_loss: 0.3071 - val_accuracy: 0.9087\n",
      "Epoch 20/20\n",
      "115/115 [==============================] - 3s 24ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.3722 - val_accuracy: 0.9130\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'C:/Users/pridh/OneDrive/Desktop/AoML/Hiragana_images',\n",
    "    target_size=(64, 64),  # Input size for the CNN model\n",
    "    batch_size=8,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data with validation on the validation data\n",
    "model.fit(train_generator, epochs=20, validation_data=validation_generator)\n",
    "\n",
    "# Load the mapping of class indices to class names from the file\n",
    "with open('class_mapping.txt', 'r', encoding='utf-8') as f:\n",
    "    class_mapping = {}\n",
    "    for line in f:\n",
    "        parts = line.strip().split(':')\n",
    "        idx = int(parts[0])\n",
    "        name = parts[1].strip()\n",
    "        class_mapping[idx] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e0269b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n",
      "The predicted hiragana character is: け\n"
     ]
    }
   ],
   "source": [
    "# Load the image to be predicted\n",
    "img_test = tf.keras.preprocessing.image.load_img(r'C:\\Users\\pridh\\OneDrive\\Desktop\\AoML\\Test Images\\2.png', target_size=(64, 64)) # \n",
    "\n",
    "# Convert the image to a numpy array\n",
    "img_test = tf.keras.preprocessing.image.img_to_array(img_test)\n",
    "\n",
    "# Rescale the image to values between 0 and 1\n",
    "img_test /= 255.\n",
    "\n",
    "# Add an extra dimension to the array to represent batch size\n",
    "img_test = tf.expand_dims(img_test, axis=0)\n",
    "\n",
    "# Make the prediction\n",
    "probs = model.predict(img_test)\n",
    "\n",
    "# Get the index of the class with highest probability\n",
    "class_idx = tf.argmax(probs, axis=1)[0].numpy()\n",
    "\n",
    "# Get the name of the class corresponding to the index\n",
    "class_name = class_mapping[class_idx]\n",
    "\n",
    "print('The predicted hiragana character is:', class_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf97b6b",
   "metadata": {},
   "source": [
    "## import numpy\n",
    "\n",
    "actual = numpy.random.binomial(1, 0.9, size = 1000)\n",
    "predicted = numpy.random.binomial(1, 0.9, size = 1000)\n",
    "from sklearn import metrics\n",
    "confusion_matrix = metrics.confusion_matrix(actual, predicted) \n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "import matplotlib.pyplot as plt\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e8b820a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.828, 'Precision': 0.8921568627450981, 'Sensitivity_recall': 0.9181614349775785, 'Specificity': 0.08333333333333333, 'F1_score': 0.9049723756906077}\n"
     ]
    }
   ],
   "source": [
    "Accuracy = metrics.accuracy_score(actual, predicted)\n",
    "Precision = metrics.precision_score(actual, predicted)\n",
    "Sensitivity_recall = metrics.recall_score(actual, predicted)\n",
    "F1_score = metrics.f1_score(actual, predicted)\n",
    "Specificity = metrics.recall_score(actual, predicted, pos_label=0)\n",
    "print({\"Accuracy\":Accuracy,\"Precision\":Precision,\"Sensitivity_recall\":Sensitivity_recall,\"Specificity\":Specificity,\"F1_score\":F1_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f8b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
